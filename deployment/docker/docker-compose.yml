# ============================================
# STEP 1.4: Docker Compose for Local Testing
# ============================================
# Docker Compose lets you run multiple containers together
# This is great for local development and testing

# version is obsolete in newer Docker Compose, but kept for compatibility

services:
  # Ollama LLM Service (for RAG and Chat)
  ollama:
    build:
      context: ../..  # Project root
      dockerfile: deployment/docker/ollama/Dockerfile
    container_name: vidstream-ollama
    ports:
      - "11434:11434"
    environment:
      # Keep model loaded in memory to avoid cold start delays
      - OLLAMA_KEEP_ALIVE=5m
      # Number of parallel requests (helps with model loading)
      - OLLAMA_NUM_PARALLEL=1
    volumes:
      - ollama-models:/root/.ollama
    networks:
      - vidstream-network
    mem_limit: 6g
    mem_reservation: 4g
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Python ML Service
  python-service:
    build:
      context: ../..  # Project root
      dockerfile: deployment/docker/python-service/Dockerfile
    container_name: vidstream-python
    ports:
      - "5001:5001"  # host:container
    environment:
      - PYTHON_SERVICE_PORT=5001
      - PYTHON_SERVICE_URL=http://python-service:5001
      - OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      # Persist ChromaDB data (vector database)
      - python-data:/tmp/vidstream/rag_knowledge
      # Mount models directory (if you want to persist downloaded models)
      - python-models:/root/.cache
    mem_limit: 8g
    mem_reservation: 4g
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5001/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - vidstream-network

  # Derby Database Server
  derby-db:
    build:
      context: ../..  # Project root
      dockerfile: deployment/docker/derby/Dockerfile
    container_name: vidstream-derby
    ports:
      - "1527:1527"
    environment:
      - DERBY_HOME=/opt/derby
    volumes:
      # Persist Derby database files
      - db-data:/opt/derby/databases
    networks:
      - vidstream-network
    healthcheck:
      test: ["CMD-SHELL", "ps aux | grep -q '[s]tartNetworkServer' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s # Give Derby time to start

  # Java REST Service
  rest-service:
    build:
      context: ../..  # Project root
      dockerfile: deployment/docker/java-rest-service/Dockerfile
    container_name: vidstream-rest
    ports:
      - "8080:8080"
    environment:
      - PYTHON_SERVICE_URL=http://python-service:5001
      - REST_API_URL=http://localhost:8080/practica5-rest-service/resources
      # Derby connection - use derby-db service name
      - DERBY_HOST=derby-db
      - DERBY_PORT=1527
    depends_on:
      python-service:
        condition: service_healthy
      derby-db:
        condition: service_healthy
    volumes:
      # Persist uploaded videos and processed files
      - video-uploads:/tmp/vidstream/uploads
      - video-processed:/tmp/vidstream/videos
      - video-audio:/tmp/vidstream/audio  # Persistent storage for extracted audio files
    networks:
      - vidstream-network

  # Web Client
  web-client:
    build:
      context: ../..  # Project root
      dockerfile: deployment/docker/web-client/Dockerfile
    container_name: vidstream-web
    ports:
      - "80:80"
    depends_on:
      - rest-service
    networks:
      - vidstream-network

  # Prometheus (for monitoring)
  prometheus:
    image: prom/prometheus:latest
    container_name: vidstream-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ../monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - vidstream-network

  # Grafana (for dashboards)
  grafana:
    image: grafana/grafana:latest
    container_name: vidstream-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - vidstream-network

# Named volumes (persistent storage)
volumes:
  python-data:
  python-models:
  db-data:
  prometheus-data:
  grafana-data:
  video-uploads:  # Persistent storage for uploaded video files
  video-processed:  # Persistent storage for processed/transcoded videos
  video-audio:  # Persistent storage for extracted audio files from videos
  ollama-models:  # Persistent storage for Ollama models

# Network (allows containers to communicate)
networks:
  vidstream-network:
    driver: bridge

